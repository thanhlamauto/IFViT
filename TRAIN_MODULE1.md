# Training Module 1: Dense Registration

## ğŸš€ Quick Start

### Kaggle TPU v5e-8 (Recommended)

```bash
cd /kaggle/working/IFViT
python ifvit-jax/train_dense_tpu.py \
    --checkpoint_dir /kaggle/working/IFViT/checkpoints/dense_reg
```

**TPU-optimized features**:
- âœ… Data parallelism vá»›i `jax.pmap`
- âœ… Batch sharding across 8 TPU cores
- âœ… Efficient gradient accumulation
- âœ… Multi-device checkpointing

### Local Development (CPU/GPU)

```bash
cd /path/to/IFViT
python ifvit-jax/train_dense.py \
    --checkpoint_dir ./checkpoints/dense_reg
```

### Kaggle Notebooks (CPU/GPU)

```bash
cd /kaggle/working/IFViT
python ifvit-jax/train_dense.py \
    --checkpoint_dir /kaggle/working/IFViT/checkpoints/dense_reg
```

## ğŸ“‹ Command Arguments

```bash
python ifvit-jax/train_dense.py \
    [--checkpoint_dir PATH] \
    [--resume_from PATH] \
    [--dataset_root PATH]  # Deprecated: khÃ´ng cáº§n ná»¯a, datasets tá»± Ä‘á»™ng load tá»« Kaggle paths
```

### Arguments

- `--checkpoint_dir` (optional): 
  - Override checkpoint directory tá»« config
  - Default: `./checkpoints/dense_reg` (local) hoáº·c `/kaggle/working/IFViT/checkpoints/dense_reg` (Kaggle)
  
- `--resume_from` (optional):
  - Resume training tá»« checkpoint
  - Example: `--resume_from ./checkpoints/dense_reg/dense_reg_epoch_50.pkl`

- `--dataset_root` (deprecated):
  - KhÃ´ng cáº§n thiáº¿t ná»¯a
  - Datasets tá»± Ä‘á»™ng load tá»« `PaperDatasetRoots()` (auto-detects Kaggle paths)

## ğŸ“Š What Happens During Training

### 1. Dataset Loading

Tá»± Ä‘á»™ng load tá»«:
- FVC2002: DB1A, DB2A, DB3A
- NIST SD301a: Partitions A, B, C, E, J, K, M, N
- NIST SD302a: Partitions A, B, C, D, E, F, U, V, L, M
- NIST SD300: Replaces MOLF

**Total**: ~25,090 original images

### 2. Data Augmentation

Má»—i image Ä‘Æ°á»£c augment:
- **ONE of 3 noise models**: Perlin noise, Erosion, hoáº·c Dilation
- **Rotation**: Â±60Â° (applied after corruption)
- **Result**: ~100,360 training images

### 3. Training Process

- **Model**: DenseRegModel (ResNet-18 + Transformer + Matching Head)
- **Loss**: L_D only (dense correspondence loss)
- **Optimizer**: AdamW with warmup cosine decay
- **Batch size**: 128 (configurable)
- **Epochs**: 100 (configurable)
- **Learning rate**: 1e-3 (configurable)

### 4. Checkpoints

- **Periodic**: `dense_reg_epoch_{N}.pkl` (every 5 epochs)
- **Final**: `dense_reg_ckpt.pkl` (sau khi training xong)

## ğŸ“ Output Structure

```
checkpoints/dense_reg/
â”œâ”€â”€ dense_reg_epoch_5.pkl
â”œâ”€â”€ dense_reg_epoch_10.pkl
â”œâ”€â”€ ...
â”œâ”€â”€ dense_reg_epoch_100.pkl
â”œâ”€â”€ dense_reg_ckpt.pkl          # Final checkpoint (dÃ¹ng cho Module 2)
â””â”€â”€ logs/
    â”œâ”€â”€ train.log
    â””â”€â”€ metrics.json
```

## ğŸ”§ Configuration

Táº¥t cáº£ hyperparameters trong `ifvit-jax/config.py` â†’ `DENSE_CONFIG`:

```python
DENSE_CONFIG = {
    "image_size": 128,
    "batch_size": 128,
    "lr": 1e-3,
    "num_epochs": 100,
    "transformer_layers": 4,
    "num_heads": 8,
    "hidden_dim": 256,
    "mlp_dim": 1024,
    "lambda_D": 1.0,  # Only L_D loss
    ...
}
```

## ğŸ“ Example Commands

### TPU Training (Kaggle TPU v5e-8)

```bash
# Kaggle TPU (Recommended - fastest)
cd /kaggle/working/IFViT
python ifvit-jax/train_dense_tpu.py \
    --checkpoint_dir /kaggle/working/IFViT/checkpoints/dense_reg
```

**TPU Benefits**:
- 8x faster vá»›i 8 TPU cores
- Effective batch size = batch_size Ã— 8
- Automatic batch sharding

### Basic Training (CPU/GPU)

```bash
# Local
python ifvit-jax/train_dense.py

# Kaggle (CPU/GPU)
cd /kaggle/working/IFViT
python ifvit-jax/train_dense.py
```

### Custom Checkpoint Directory

```bash
# Local
python ifvit-jax/train_dense.py \
    --checkpoint_dir ./my_checkpoints/dense_reg

# Kaggle
python ifvit-jax/train_dense.py \
    --checkpoint_dir /kaggle/working/IFViT/my_checkpoints/dense_reg
```

### Resume Training

```bash
# Resume from epoch 50
python ifvit-jax/train_dense.py \
    --resume_from ./checkpoints/dense_reg/dense_reg_epoch_50.pkl
```

## âš ï¸ Important Notes

1. **TPU vs CPU/GPU**:
   - **TPU**: DÃ¹ng `train_dense_tpu.py` (tá»‘i Æ°u cho TPU v5e-8)
   - **CPU/GPU**: DÃ¹ng `train_dense.py` (single device)
   - TPU version tá»± Ä‘á»™ng shard batch across 8 cores

2. **Datasets tá»± Ä‘á»™ng load**: KhÃ´ng cáº§n chá»‰ Ä‘á»‹nh `--dataset_root`, datasets tá»± Ä‘á»™ng detect tá»« Kaggle paths hoáº·c local paths

3. **Checkpoint path**: Module 2 sáº½ tá»± Ä‘á»™ng load tá»« `./checkpoints/dense_reg/dense_reg_ckpt.pkl` (hoáº·c path trong config)

4. **Training time**: 
   - ~100 epochs vá»›i ~100k training pairs
   - **TPU v5e-8**: ~2-4 giá» (8 cores parallel)
   - **GPU**: ~8-16 giá» (single GPU)
   - **CPU**: ~2-3 ngÃ y (single CPU)

5. **Memory**: 
   - Batch size 128 vá»›i 128Ã—128 images
   - **TPU**: Per-device batch = 128/8 = 16 (efficient)
   - **GPU**: Cáº§n ~8-16GB GPU memory

## ğŸ” Monitoring Training

Logs Ä‘Æ°á»£c lÆ°u táº¡i:
- `{checkpoint_dir}/logs/train.log`
- `{checkpoint_dir}/logs/metrics.json`

Checkpoints Ä‘Æ°á»£c lÆ°u táº¡i:
- `{checkpoint_dir}/dense_reg_epoch_{N}.pkl` (periodic)
- `{checkpoint_dir}/dense_reg_ckpt.pkl` (final)

## âœ… After Training

Sau khi training xong, checkpoint final sáº½ Ä‘Æ°á»£c lÆ°u táº¡i:
- Local: `./checkpoints/dense_reg/dense_reg_ckpt.pkl`
- Kaggle: `/kaggle/working/IFViT/checkpoints/dense_reg/dense_reg_ckpt.pkl`

Checkpoint nÃ y sáº½ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ train Module 2:

```bash
python ifvit-jax/train_match.py \
    --pretrained_ckpt ./checkpoints/dense_reg/dense_reg_ckpt.pkl \
    --num_classes 100
```

